application {
  env = "local"
  name = "KafkaMessgaeProducer"
}

play {
  http.secret.key = "ejz4H^9nAz;4f]7=geeRA>=7>:NK50h`fuz35h/ndH:ThaQcEfpm^MhV`Ywd/91u"
  i18n {
    langs = ["en"]
  }
  filters.hosts {
    allowed = ["."]
  }
}

kafka {
  server = "localhost:9092"
  group.id = "adis-customer-request-processor"
  topic.names {
    in.customer_input_request = "adis.cip.customer_input_request"
  }
}

akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  log-dead-letters = 0
  loglevel = "DEBUG"
  stdout-loglevel = "INFO"
  actor {
    debug {
      receive = off
      autoreceive = off
      lifecycle = off
    }
  }
  kafka.producer {
    # Tuning parameter of how many sends that can run in parallel.
    parallelism = 100

    # How long to wait for `KafkaProducer.close`
    close-timeout = 60s

    # Fully qualified config path which holds the dispatcher configuration
    # to be used by the producer stages. Some blocking may occur.
    # When this value is empty, the dispatcher configured for the stream
    # will be used.
    use-dispatcher = "akka.kafka.default-dispatcher"

    # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
    # can be defined in this configuration section.
    kafka-clients {
      bootstrap.servers = ${kafka.server}
      message.send.max.retries = 3
      key.serializer = "org.apache.kafka.common.serialization.StringSerializer"
      value.serializer = "org.apache.kafka.common.serialization.ByteArraySerializer"
    }
  }
  kafka.consumer {
    # Tuning property of scheduled polls.
    poll-interval = 40ms

    # Tuning property of the `KafkaConsumer.poll` parameter.
    # Note that non-zero value means that blocking of the thread that
    # is executing the stage will be blocked.
    poll-timeout = 50s

    # The stage will be await outstanding offset commit requests before
    # shutting down, but if that takes longer than this timeout it will
    # stop forcefully.
    stop-timeout = 30s

    # How long to wait for `KafkaConsumer.close`
    close-timeout = 20s

    # If offset commit requests are not completed within this timeout
    # the returned Future is completed `TimeoutException`.
    commit-timeout = 15s

    # If the KafkaConsumer can't connect to the broker the poll will be
    # aborted after this timeout. The KafkaConsumerActor will throw
    # org.apache.kafka.common.errors.WakeupException which will be ignored
    # until max-wakeups limit gets exceeded.
    wakeup-timeout = 60s

    # After exceeding maxinum wakeups the consumer will stop and the stage will fail.
    max-wakeups = 4800

    # Fully qualified config path which holds the dispatcher configuration
    # to be used by the KafkaConsumerActor. Some blocking may occur.
    use-dispatcher = "akka.kafka.default-dispatcher"

    # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
    # can be defined in this configuration section.
    kafka-clients {
      # Disable auto-commit by default
      enable.auto.commit = false
      bootstrap.servers: ${kafka.server}
      key.deserializer: "org.apache.kafka.common.serialization.StringDeserializer"
      value.deserializer: "org.apache.kafka.common.serialization.StringDeserializer"
      group.id: ${kafka.group.id}
      auto.offset.reset: "earliest"
    }
  }
}








